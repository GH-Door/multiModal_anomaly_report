{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD Context MCQ Ablation (Colab)\n",
    "\n",
    "This notebook compares three settings on the exact same sampled images:\n",
    "1. no AD\n",
    "2. legacy AD context\n",
    "3. v2 AD context\n",
    "\n",
    "Outputs include overall accuracy and per-question-type accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import shlex\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== User config =====\n",
    "REPO_ROOT = Path('/content/multimodal-anomaly-report-generation')\n",
    "DATA_ROOT = '/content/dataset/MMAD'\n",
    "MMAD_JSON = '/content/dataset/MMAD/mmad_10classes.json'\n",
    "CHECKPOINT_DIR = '/content/dataset/MMAD/patchcore_ckpt'\n",
    "LLM_MODEL = 'internvl3.5-2b'\n",
    "FEW_SHOT = 1\n",
    "BATCH_MODE = 'true'\n",
    "SAMPLE_PER_FOLDER = 3\n",
    "SAMPLE_SEED = 42\n",
    "\n",
    "# Optional: use only part of sampled images for quick debug\n",
    "MAX_IMAGES = None  # e.g., 100\n",
    "\n",
    "RUN_TAG = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "WORK_DIR = REPO_ROOT / 'outputs' / 'eval_ablation' / RUN_TAG\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAMPLED_MMAD_JSON = WORK_DIR / '_sampled_mmad.json'\n",
    "AD_LEGACY_JSON = WORK_DIR / 'ad_legacy.json'\n",
    "AD_V2_JSON = WORK_DIR / 'ad_v2.json'\n",
    "\n",
    "OUT_NO_AD = WORK_DIR / 'no_ad'\n",
    "OUT_LEGACY = WORK_DIR / 'legacy_ad'\n",
    "OUT_V2 = WORK_DIR / 'v2_ad'\n",
    "\n",
    "for p in [OUT_NO_AD, OUT_LEGACY, OUT_V2]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('WORK_DIR:', WORK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(cmd: str, cwd: Path = REPO_ROOT):\n",
    "    print('\\n$ ' + cmd)\n",
    "    proc = subprocess.run(\n",
    "        cmd,\n",
    "        cwd=str(cwd),\n",
    "        shell=True,\n",
    "        text=True,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "    )\n",
    "    print(proc.stdout)\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(f'Command failed ({proc.returncode}): {cmd}')\n",
    "\n",
    "\n",
    "def stratified_sample_paths(image_paths, n_per_folder: int, seed: int = 42):\n",
    "    rng = random.Random(seed)\n",
    "    folders = defaultdict(list)\n",
    "    for path in image_paths:\n",
    "        parts = path.split('/')\n",
    "        if len(parts) >= 4:\n",
    "            key = f'{parts[0]}/{parts[1]}/{parts[3]}'\n",
    "        elif len(parts) >= 2:\n",
    "            key = f'{parts[0]}/{parts[1]}'\n",
    "        else:\n",
    "            key = 'unknown'\n",
    "        folders[key].append(path)\n",
    "\n",
    "    sampled = []\n",
    "    for key in sorted(folders.keys()):\n",
    "        imgs = folders[key]\n",
    "        sampled.extend(rng.sample(imgs, min(n_per_folder, len(imgs))))\n",
    "    return sampled\n",
    "\n",
    "\n",
    "def build_sampled_mmad(input_json: str, output_json: Path, n_per_folder: int, seed: int = 42, max_images=None):\n",
    "    with open(input_json, 'r', encoding='utf-8') as f:\n",
    "        mmad_data = json.load(f)\n",
    "\n",
    "    sampled_paths = stratified_sample_paths(list(mmad_data.keys()), n_per_folder=n_per_folder, seed=seed)\n",
    "    if max_images is not None:\n",
    "        sampled_paths = sampled_paths[:max_images]\n",
    "\n",
    "    sampled_data = {k: mmad_data[k] for k in sampled_paths}\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(sampled_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    n_good = sum('/good/' in p for p in sampled_paths)\n",
    "    print('sampled images:', len(sampled_paths), 'good:', n_good, 'anomaly:', len(sampled_paths) - n_good)\n",
    "    print('sample json:', output_json)\n",
    "\n",
    "\n",
    "def latest_meta(output_dir: Path):\n",
    "    metas = sorted(output_dir.glob('*.meta.json'), key=lambda p: p.stat().st_mtime)\n",
    "    if not metas:\n",
    "        raise FileNotFoundError(f'No .meta.json found in {output_dir}')\n",
    "    return metas[-1]\n",
    "\n",
    "\n",
    "def question_type_accuracy(answers_json_path: Path):\n",
    "    with open(answers_json_path, 'r', encoding='utf-8') as f:\n",
    "        rows = json.load(f)\n",
    "\n",
    "    by_type = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "    for r in rows:\n",
    "        qt = r.get('question_type', 'unknown')\n",
    "        by_type[qt]['total'] += 1\n",
    "        if r.get('gpt_answer') == r.get('correct_answer'):\n",
    "            by_type[qt]['correct'] += 1\n",
    "\n",
    "    out = []\n",
    "    for qt, s in by_type.items():\n",
    "        acc = 100.0 * s['correct'] / s['total'] if s['total'] else 0.0\n",
    "        out.append({'question_type': qt, 'total': s['total'], 'correct': s['correct'], 'accuracy': round(acc, 2)})\n",
    "    return pd.DataFrame(out).sort_values(['accuracy', 'total'], ascending=[False, False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_sampled_mmad(\n",
    "    input_json=MMAD_JSON,\n",
    "    output_json=SAMPLED_MMAD_JSON,\n",
    "    n_per_folder=SAMPLE_PER_FOLDER,\n",
    "    seed=SAMPLE_SEED,\n",
    "    max_images=MAX_IMAGES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build legacy AD context JSON\n",
    "cmd_legacy = ' '.join([\n",
    "    'python scripts/run_ad_inference.py',\n",
    "    '--backend ckpt',\n",
    "    f'--checkpoint-dir {shlex.quote(CHECKPOINT_DIR)}',\n",
    "    f'--data-root {shlex.quote(DATA_ROOT)}',\n",
    "    f'--mmad-json {shlex.quote(str(SAMPLED_MMAD_JSON))}',\n",
    "    f'--output {shlex.quote(str(AD_LEGACY_JSON))}',\n",
    "    '--output-format report',\n",
    "    '--device cpu',\n",
    "    '--context-mode legacy',\n",
    "])\n",
    "run_cmd(cmd_legacy)\n",
    "\n",
    "# Build v2 AD context JSON\n",
    "cmd_v2 = ' '.join([\n",
    "    'python scripts/run_ad_inference.py',\n",
    "    '--backend ckpt',\n",
    "    f'--checkpoint-dir {shlex.quote(CHECKPOINT_DIR)}',\n",
    "    f'--data-root {shlex.quote(DATA_ROOT)}',\n",
    "    f'--mmad-json {shlex.quote(str(SAMPLED_MMAD_JSON))}',\n",
    "    f'--output {shlex.quote(str(AD_V2_JSON))}',\n",
    "    '--output-format report',\n",
    "    '--device cpu',\n",
    "    '--context-mode v2',\n",
    "])\n",
    "run_cmd(cmd_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no AD\n",
    "cmd_no_ad = ' '.join([\n",
    "    'python scripts/run_experiment.py',\n",
    "    f'--llm {shlex.quote(LLM_MODEL)}',\n",
    "    '--ad-model null',\n",
    "    f'--data-root {shlex.quote(DATA_ROOT)}',\n",
    "    f'--mmad-json {shlex.quote(str(SAMPLED_MMAD_JSON))}',\n",
    "    f'--few-shot {FEW_SHOT}',\n",
    "    f'--batch-mode {BATCH_MODE}',\n",
    "    f'--output-dir {shlex.quote(str(OUT_NO_AD))}',\n",
    "])\n",
    "run_cmd(cmd_no_ad)\n",
    "\n",
    "# legacy AD context\n",
    "cmd_legacy_eval = ' '.join([\n",
    "    'python scripts/run_experiment.py',\n",
    "    f'--llm {shlex.quote(LLM_MODEL)}',\n",
    "    '--ad-model patchcore',\n",
    "    f'--ad-output {shlex.quote(str(AD_LEGACY_JSON))}',\n",
    "    f'--data-root {shlex.quote(DATA_ROOT)}',\n",
    "    f'--mmad-json {shlex.quote(str(SAMPLED_MMAD_JSON))}',\n",
    "    f'--few-shot {FEW_SHOT}',\n",
    "    f'--batch-mode {BATCH_MODE}',\n",
    "    f'--output-dir {shlex.quote(str(OUT_LEGACY))}',\n",
    "])\n",
    "run_cmd(cmd_legacy_eval)\n",
    "\n",
    "# v2 AD context\n",
    "cmd_v2_eval = ' '.join([\n",
    "    'python scripts/run_experiment.py',\n",
    "    f'--llm {shlex.quote(LLM_MODEL)}',\n",
    "    '--ad-model patchcore',\n",
    "    f'--ad-output {shlex.quote(str(AD_V2_JSON))}',\n",
    "    f'--data-root {shlex.quote(DATA_ROOT)}',\n",
    "    f'--mmad-json {shlex.quote(str(SAMPLED_MMAD_JSON))}',\n",
    "    f'--few-shot {FEW_SHOT}',\n",
    "    f'--batch-mode {BATCH_MODE}',\n",
    "    f'--output-dir {shlex.quote(str(OUT_V2))}',\n",
    "])\n",
    "run_cmd(cmd_v2_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_no_ad = json.load(open(latest_meta(OUT_NO_AD), 'r', encoding='utf-8'))\n",
    "meta_legacy = json.load(open(latest_meta(OUT_LEGACY), 'r', encoding='utf-8'))\n",
    "meta_v2 = json.load(open(latest_meta(OUT_V2), 'r', encoding='utf-8'))\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {'setting': 'no_ad', 'accuracy': meta_no_ad['accuracy'], 'processed': meta_no_ad['processed'], 'errors': meta_no_ad['errors'], 'answers_file': meta_no_ad['answers_file']},\n",
    "    {'setting': 'legacy_ad_context', 'accuracy': meta_legacy['accuracy'], 'processed': meta_legacy['processed'], 'errors': meta_legacy['errors'], 'answers_file': meta_legacy['answers_file']},\n",
    "    {'setting': 'v2_ad_context', 'accuracy': meta_v2['accuracy'], 'processed': meta_v2['processed'], 'errors': meta_v2['errors'], 'answers_file': meta_v2['answers_file']},\n",
    "]).sort_values('accuracy', ascending=False).reset_index(drop=True)\n",
    "display(summary)\n",
    "\n",
    "# Per-question-type view (focus on anomaly/localization)\n",
    "df_no_ad = question_type_accuracy(Path(meta_no_ad['answers_file']))\n",
    "df_legacy = question_type_accuracy(Path(meta_legacy['answers_file']))\n",
    "df_v2 = question_type_accuracy(Path(meta_v2['answers_file']))\n",
    "\n",
    "pivot = (\n",
    "    df_no_ad[['question_type', 'accuracy']].rename(columns={'accuracy': 'no_ad'})\n",
    "    .merge(df_legacy[['question_type', 'accuracy']].rename(columns={'accuracy': 'legacy'}), on='question_type', how='outer')\n",
    "    .merge(df_v2[['question_type', 'accuracy']].rename(columns={'accuracy': 'v2'}), on='question_type', how='outer')\n",
    "    .fillna(0.0)\n",
    ")\n",
    "pivot['delta_v2_vs_legacy'] = (pivot['v2'] - pivot['legacy']).round(2)\n",
    "pivot['delta_v2_vs_no_ad'] = (pivot['v2'] - pivot['no_ad']).round(2)\n",
    "pivot = pivot.sort_values('delta_v2_vs_legacy', ascending=False).reset_index(drop=True)\n",
    "display(pivot)\n",
    "\n",
    "print('Work directory:', WORK_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
